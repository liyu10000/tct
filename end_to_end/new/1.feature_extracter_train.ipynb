{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End to end model:feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1 import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "from keras import optimizers\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 build pretrained modelÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "###body###\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "drop_fc1 (Dropout)           (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "drop_fc2 (Dropout)           (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 124,887,618\n",
      "Trainable params: 104,863,234\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n",
      "###whole###\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 224, 224, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 224, 224, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 224, 224, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 224, 224, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 2)            124887618   lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Concatenate)       (None, 2)            0           model_1[1][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "                                                                 model_1[3][0]                    \n",
      "                                                                 model_1[4][0]                    \n",
      "==================================================================================================\n",
      "Total params: 124,887,618\n",
      "Trainable params: 104,863,234\n",
      "Non-trainable params: 20,024,384\n",
      "__________________________________________________________________________________________________\n",
      "###parallel###\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    input_tensor = Input((224, 224, 3))\n",
    "    x = Lambda(vgg19.preprocess_input)(input_tensor)\n",
    "\n",
    "    base_model = VGG19(input_tensor=x, weights='imagenet', include_top=False)\n",
    "    base_model.summary()\n",
    "\n",
    "    print(\"###body###\")\n",
    "\n",
    "    m_out = base_model.output\n",
    "\n",
    "    flatten = Flatten(name='flatten')(m_out)\n",
    "\n",
    "    fc1 = Dense(4096, activation='relu', name='fc1')(flatten)\n",
    "    drop_fc1 = Dropout(0.5, name='drop_fc1')(fc1)\n",
    "\n",
    "    fc2 = Dense(512, activation='relu', name='fc2')(drop_fc1)\n",
    "    drop_fc2 = Dropout(0.5, name='drop_fc2')(fc2)\n",
    "\n",
    "    predictions = Dense(2, activation='softmax', name='predictions')(drop_fc2)\n",
    "\n",
    "    for layer in base_model.layers:  \n",
    "        layer.trainable = False\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    model.summary()\n",
    "    print(\"###whole###\")\n",
    "\n",
    "    sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "parallel_model = multi_gpu_model(model, gpus=4)\n",
    "parallel_model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "parallel_model.summary()\n",
    "print(\"###parallel###\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 build param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 5\n",
    "\n",
    "total_imgs_num = 27140 + 3023\n",
    "train_imgs_num = 27140\n",
    "valid_imgs_num = 3023\n",
    "\n",
    "img_size = (224, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 build data & first train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27140 images belonging to 2 classes.\n",
      "Found 3023 images belonging to 2 classes.\n",
      "Epoch 1/5\n",
      "212/212 [==============================] - 212s 999ms/step - loss: 5.3770 - acc: 0.6654 - val_loss: 5.3599 - val_acc: 0.6675\n",
      "Epoch 2/5\n"
     ]
    }
   ],
   "source": [
    "img_gen_t = ImageDataGenerator()\n",
    "\n",
    "train_generator = img_gen_t.flow_from_directory(\"/home/tsimage/high_speed_data/tct_data_samesize_0718_224/train\", \n",
    "                                                img_size, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "img_gen_v = ImageDataGenerator()\n",
    "valid_generator = img_gen_v.flow_from_directory(\"/home/tsimage/high_speed_data/tct_data_samesize_0718_224/valid\",\n",
    "                                                img_size, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "parallel_model.fit_generator(generator=train_generator, \n",
    "                             steps_per_epoch=train_imgs_num//batch_size, \n",
    "                             epochs=epochs, \n",
    "                             verbose=1,\n",
    "                             validation_data=valid_generator, \n",
    "                             validation_steps=valid_imgs_num//batch_size)\n",
    "\n",
    "model.save_weights(\"vgg19_first_train.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 build finetune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "lambda_6 (Lambda)            (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "###body###\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "lambda_6 (Lambda)            (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "drop_fc1 (Dropout)           (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "drop_fc2 (Dropout)           (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 124,887,618\n",
      "Trainable params: 124,887,618\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "###whole###\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 224, 224, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 224, 224, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 224, 224, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 224, 224, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Model)                 (None, 2)            124887618   lambda_7[0][0]                   \n",
      "                                                                 lambda_8[0][0]                   \n",
      "                                                                 lambda_9[0][0]                   \n",
      "                                                                 lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Concatenate)       (None, 2)            0           model_3[1][0]                    \n",
      "                                                                 model_3[2][0]                    \n",
      "                                                                 model_3[3][0]                    \n",
      "                                                                 model_3[4][0]                    \n",
      "==================================================================================================\n",
      "Total params: 124,887,618\n",
      "Trainable params: 124,887,618\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "###parallel###\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    input_tensor = Input((224, 224, 3))\n",
    "    x = Lambda(vgg19.preprocess_input)(input_tensor)\n",
    "\n",
    "    base_model = VGG19(input_tensor=x, weights='imagenet', include_top=False)\n",
    "    base_model.summary()\n",
    "\n",
    "    print(\"###body###\")\n",
    "\n",
    "    m_out = base_model.output\n",
    "\n",
    "    flatten = Flatten(name='flatten')(m_out)\n",
    "\n",
    "    fc1 = Dense(4096, activation='relu', name='fc1')(flatten)\n",
    "    drop_fc1 = Dropout(0.5, name='drop_fc1')(fc1)\n",
    "\n",
    "    fc2 = Dense(512, activation='relu', name='fc2')(drop_fc1)\n",
    "    drop_fc2 = Dropout(0.5, name='drop_fc2')(fc2)\n",
    "\n",
    "    predictions = Dense(2, activation='softmax', name='predictions')(drop_fc2)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    model.load_weights('vgg19_first_train.h5')\n",
    "    model.summary()\n",
    "    print(\"###whole###\")\n",
    "\n",
    "    sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "parallel_model = multi_gpu_model(model, gpus=4)\n",
    "parallel_model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "parallel_model.summary()\n",
    "print(\"###parallel###\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 build param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 100\n",
    "\n",
    "total_imgs_num = 27140 + 3023\n",
    "train_imgs_num = 27140\n",
    "valid_imgs_num = 3023\n",
    "\n",
    "img_size = (224, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 build data & finetune train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27140 images belonging to 2 classes.\n",
      "Found 3023 images belonging to 2 classes.\n",
      "Epoch 1/100\n",
      "212/212 [==============================] - 231s 1s/step - loss: 0.4616 - acc: 0.7783 - val_loss: 0.3607 - val_acc: 0.8336\n",
      "Epoch 2/100\n",
      "212/212 [==============================] - 230s 1s/step - loss: 0.4304 - acc: 0.7961 - val_loss: 0.3182 - val_acc: 0.8536\n",
      "Epoch 3/100\n",
      "212/212 [==============================] - 229s 1s/step - loss: 0.3542 - acc: 0.8364 - val_loss: 0.3130 - val_acc: 0.8512\n",
      "Epoch 4/100\n",
      "212/212 [==============================] - 229s 1s/step - loss: 0.3317 - acc: 0.8511 - val_loss: 0.2614 - val_acc: 0.8947\n",
      "Epoch 5/100\n",
      "212/212 [==============================] - 229s 1s/step - loss: 0.3321 - acc: 0.8515 - val_loss: 0.3174 - val_acc: 0.8556\n",
      "Epoch 6/100\n",
      "212/212 [==============================] - 228s 1s/step - loss: 0.3092 - acc: 0.8626 - val_loss: 0.2270 - val_acc: 0.9059\n",
      "Epoch 7/100\n",
      "212/212 [==============================] - 228s 1s/step - loss: 0.2958 - acc: 0.8681 - val_loss: 0.2405 - val_acc: 0.8971\n",
      "Epoch 8/100\n",
      "212/212 [==============================] - 228s 1s/step - loss: 0.2847 - acc: 0.8768 - val_loss: 0.2578 - val_acc: 0.8818\n",
      "Epoch 9/100\n",
      "212/212 [==============================] - 228s 1s/step - loss: 0.2713 - acc: 0.8806 - val_loss: 0.2500 - val_acc: 0.8886\n",
      "Epoch 10/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.2673 - acc: 0.8823 - val_loss: 0.2057 - val_acc: 0.9093\n",
      "Epoch 11/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.2645 - acc: 0.8846 - val_loss: 0.1849 - val_acc: 0.9283\n",
      "Epoch 12/100\n",
      "212/212 [==============================] - 226s 1s/step - loss: 0.2585 - acc: 0.8874 - val_loss: 0.1993 - val_acc: 0.9134\n",
      "Epoch 13/100\n",
      "212/212 [==============================] - 226s 1s/step - loss: 0.2565 - acc: 0.8866 - val_loss: 0.1833 - val_acc: 0.9260\n",
      "Epoch 14/100\n",
      "212/212 [==============================] - 228s 1s/step - loss: 0.2493 - acc: 0.8917 - val_loss: 0.1806 - val_acc: 0.9280\n",
      "Epoch 15/100\n",
      "212/212 [==============================] - 226s 1s/step - loss: 0.2619 - acc: 0.8856 - val_loss: 0.1901 - val_acc: 0.9236\n",
      "Epoch 16/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.2404 - acc: 0.8949 - val_loss: 0.1792 - val_acc: 0.9273\n",
      "Epoch 17/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.2371 - acc: 0.8973 - val_loss: 0.1704 - val_acc: 0.9327\n",
      "Epoch 18/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.2345 - acc: 0.8960 - val_loss: 0.2288 - val_acc: 0.9062\n",
      "Epoch 19/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.2238 - acc: 0.9046 - val_loss: 0.1755 - val_acc: 0.9263\n",
      "Epoch 20/100\n",
      "212/212 [==============================] - 226s 1s/step - loss: 0.2271 - acc: 0.9018 - val_loss: 0.1625 - val_acc: 0.9334\n",
      "Epoch 21/100\n",
      "212/212 [==============================] - 226s 1s/step - loss: 0.2213 - acc: 0.9037 - val_loss: 0.1811 - val_acc: 0.9239\n",
      "Epoch 22/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.2214 - acc: 0.9043 - val_loss: 0.1817 - val_acc: 0.9260\n",
      "Epoch 23/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.2159 - acc: 0.9068 - val_loss: 0.1755 - val_acc: 0.9273\n",
      "Epoch 24/100\n",
      "212/212 [==============================] - 225s 1s/step - loss: 0.2103 - acc: 0.9085 - val_loss: 0.1613 - val_acc: 0.9351\n",
      "Epoch 25/100\n",
      "212/212 [==============================] - 226s 1s/step - loss: 0.4944 - acc: 0.7555 - val_loss: 0.4029 - val_acc: 0.8060\n",
      "Epoch 26/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.3862 - acc: 0.8201 - val_loss: 0.2806 - val_acc: 0.8818\n",
      "Epoch 27/100\n",
      "212/212 [==============================] - 226s 1s/step - loss: 0.2953 - acc: 0.8680 - val_loss: 0.2066 - val_acc: 0.9209\n",
      "Epoch 28/100\n",
      "212/212 [==============================] - 226s 1s/step - loss: 0.2588 - acc: 0.8858 - val_loss: 0.1889 - val_acc: 0.9249\n",
      "Epoch 29/100\n",
      "212/212 [==============================] - 228s 1s/step - loss: 0.2396 - acc: 0.8952 - val_loss: 0.1970 - val_acc: 0.9175\n",
      "Epoch 30/100\n",
      "212/212 [==============================] - 226s 1s/step - loss: 0.2281 - acc: 0.9020 - val_loss: 0.2015 - val_acc: 0.9073\n",
      "Epoch 31/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.2222 - acc: 0.9019 - val_loss: 0.1891 - val_acc: 0.9178\n",
      "Epoch 32/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.2219 - acc: 0.9026 - val_loss: 0.1700 - val_acc: 0.9273\n",
      "Epoch 33/100\n",
      "212/212 [==============================] - 226s 1s/step - loss: 0.2155 - acc: 0.9052 - val_loss: 0.1511 - val_acc: 0.9378\n",
      "Epoch 34/100\n",
      "212/212 [==============================] - 226s 1s/step - loss: 0.2137 - acc: 0.9075 - val_loss: 0.1506 - val_acc: 0.9402\n",
      "Epoch 35/100\n",
      "212/212 [==============================] - 228s 1s/step - loss: 0.2059 - acc: 0.9104 - val_loss: 0.1661 - val_acc: 0.9300\n",
      "Epoch 36/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.2024 - acc: 0.9114 - val_loss: 0.1673 - val_acc: 0.9276\n",
      "Epoch 37/100\n",
      "212/212 [==============================] - 226s 1s/step - loss: 0.2028 - acc: 0.9127 - val_loss: 0.1456 - val_acc: 0.9416\n",
      "Epoch 38/100\n",
      "212/212 [==============================] - 226s 1s/step - loss: 0.1990 - acc: 0.9142 - val_loss: 0.1588 - val_acc: 0.9341\n",
      "Epoch 39/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.1933 - acc: 0.9169 - val_loss: 0.1538 - val_acc: 0.9406\n",
      "Epoch 40/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.1943 - acc: 0.9164 - val_loss: 0.1494 - val_acc: 0.9416\n",
      "Epoch 41/100\n",
      "212/212 [==============================] - 228s 1s/step - loss: 0.1905 - acc: 0.9173 - val_loss: 0.1395 - val_acc: 0.9474\n",
      "Epoch 42/100\n",
      "212/212 [==============================] - 225s 1s/step - loss: 0.1894 - acc: 0.9162 - val_loss: 0.1533 - val_acc: 0.9389\n",
      "Epoch 43/100\n",
      "212/212 [==============================] - 228s 1s/step - loss: 0.1849 - acc: 0.9201 - val_loss: 0.1395 - val_acc: 0.9467\n",
      "Epoch 44/100\n",
      "212/212 [==============================] - 226s 1s/step - loss: 0.1960 - acc: 0.9175 - val_loss: 0.1415 - val_acc: 0.9460\n",
      "Epoch 45/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.1884 - acc: 0.9199 - val_loss: 0.1528 - val_acc: 0.9406\n",
      "Epoch 46/100\n",
      "212/212 [==============================] - 226s 1s/step - loss: 0.2320 - acc: 0.8994 - val_loss: 0.1504 - val_acc: 0.9344\n",
      "Epoch 47/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.1848 - acc: 0.9208 - val_loss: 0.1465 - val_acc: 0.9450\n",
      "Epoch 48/100\n",
      "212/212 [==============================] - 226s 1s/step - loss: 0.1948 - acc: 0.9160 - val_loss: 0.1568 - val_acc: 0.9402\n",
      "Epoch 49/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.1783 - acc: 0.9224 - val_loss: 0.1428 - val_acc: 0.9429\n",
      "Epoch 50/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.1776 - acc: 0.9243 - val_loss: 0.1504 - val_acc: 0.9372\n",
      "Epoch 51/100\n",
      "212/212 [==============================] - 226s 1s/step - loss: 0.1826 - acc: 0.9210 - val_loss: 0.1410 - val_acc: 0.9426\n",
      "Epoch 52/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.1753 - acc: 0.9264 - val_loss: 0.1541 - val_acc: 0.9402\n",
      "Epoch 53/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.1755 - acc: 0.9255 - val_loss: 0.1535 - val_acc: 0.9429\n",
      "Epoch 54/100\n",
      "212/212 [==============================] - 228s 1s/step - loss: 0.1657 - acc: 0.9279 - val_loss: 0.1496 - val_acc: 0.9385\n",
      "Epoch 55/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.1662 - acc: 0.9295 - val_loss: 0.1453 - val_acc: 0.9477\n",
      "Epoch 56/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.1670 - acc: 0.9270 - val_loss: 0.1371 - val_acc: 0.9470\n",
      "Epoch 57/100\n",
      "212/212 [==============================] - 226s 1s/step - loss: 0.1669 - acc: 0.9291 - val_loss: 0.1455 - val_acc: 0.9392\n",
      "Epoch 58/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.1664 - acc: 0.9277 - val_loss: 0.1296 - val_acc: 0.9518\n",
      "Epoch 59/100\n",
      "212/212 [==============================] - 226s 1s/step - loss: 0.1611 - acc: 0.9302 - val_loss: 0.1471 - val_acc: 0.9433\n",
      "Epoch 60/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.1622 - acc: 0.9298 - val_loss: 0.1376 - val_acc: 0.9487\n",
      "Epoch 61/100\n",
      "212/212 [==============================] - 226s 1s/step - loss: 0.1598 - acc: 0.9325 - val_loss: 0.1525 - val_acc: 0.9378\n",
      "Epoch 62/100\n",
      "212/212 [==============================] - 226s 1s/step - loss: 0.1558 - acc: 0.9318 - val_loss: 0.1488 - val_acc: 0.9443\n",
      "Epoch 63/100\n",
      "212/212 [==============================] - 226s 1s/step - loss: 0.1608 - acc: 0.9304 - val_loss: 0.1370 - val_acc: 0.9497\n",
      "Epoch 64/100\n",
      "212/212 [==============================] - 226s 1s/step - loss: 0.1548 - acc: 0.9336 - val_loss: 0.1454 - val_acc: 0.9487\n",
      "Epoch 65/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.1669 - acc: 0.9281 - val_loss: 0.1458 - val_acc: 0.9406\n",
      "Epoch 66/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.1522 - acc: 0.9357 - val_loss: 0.1375 - val_acc: 0.9487\n",
      "Epoch 67/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.1504 - acc: 0.9371 - val_loss: 0.1483 - val_acc: 0.9399\n",
      "Epoch 68/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.1515 - acc: 0.9351 - val_loss: 0.1304 - val_acc: 0.9467\n",
      "Epoch 69/100\n",
      "212/212 [==============================] - 226s 1s/step - loss: 0.1502 - acc: 0.9358 - val_loss: 0.1539 - val_acc: 0.9453\n",
      "Epoch 70/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.1474 - acc: 0.9362 - val_loss: 0.1331 - val_acc: 0.9504\n",
      "Epoch 71/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.1454 - acc: 0.9369 - val_loss: 0.1345 - val_acc: 0.9528\n",
      "Epoch 72/100\n",
      "212/212 [==============================] - 226s 1s/step - loss: 0.1471 - acc: 0.9368 - val_loss: 0.1371 - val_acc: 0.9484\n",
      "Epoch 73/100\n",
      "212/212 [==============================] - 228s 1s/step - loss: 0.1429 - acc: 0.9402 - val_loss: 0.1320 - val_acc: 0.9501\n",
      "Epoch 74/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.1466 - acc: 0.9356 - val_loss: 0.1186 - val_acc: 0.9555\n",
      "Epoch 75/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.1453 - acc: 0.9365 - val_loss: 0.1341 - val_acc: 0.9504\n",
      "Epoch 76/100\n",
      "212/212 [==============================] - 226s 1s/step - loss: 0.1447 - acc: 0.9390 - val_loss: 0.1310 - val_acc: 0.9538\n",
      "Epoch 77/100\n",
      "212/212 [==============================] - 226s 1s/step - loss: 0.1440 - acc: 0.9379 - val_loss: 0.1580 - val_acc: 0.9426\n",
      "Epoch 78/100\n",
      "212/212 [==============================] - 228s 1s/step - loss: 0.1417 - acc: 0.9392 - val_loss: 0.1361 - val_acc: 0.9504\n",
      "Epoch 79/100\n",
      "212/212 [==============================] - 226s 1s/step - loss: 0.1476 - acc: 0.9359 - val_loss: 0.1279 - val_acc: 0.9480\n",
      "Epoch 80/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.1456 - acc: 0.9359 - val_loss: 0.1381 - val_acc: 0.9423\n",
      "Epoch 81/100\n",
      "212/212 [==============================] - 226s 1s/step - loss: 0.1486 - acc: 0.9363 - val_loss: 0.1269 - val_acc: 0.9541\n",
      "Epoch 82/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.1388 - acc: 0.9415 - val_loss: 0.1412 - val_acc: 0.9440\n",
      "Epoch 83/100\n",
      "212/212 [==============================] - 226s 1s/step - loss: 0.1485 - acc: 0.9369 - val_loss: 0.1203 - val_acc: 0.9555\n",
      "Epoch 84/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.1398 - acc: 0.9423 - val_loss: 0.1483 - val_acc: 0.9470\n",
      "Epoch 85/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.1355 - acc: 0.9419 - val_loss: 0.1459 - val_acc: 0.9501\n",
      "Epoch 86/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.1376 - acc: 0.9417 - val_loss: 0.1228 - val_acc: 0.9531\n",
      "Epoch 87/100\n",
      "212/212 [==============================] - 225s 1s/step - loss: 0.1390 - acc: 0.9388 - val_loss: 0.1448 - val_acc: 0.9436\n",
      "Epoch 88/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.1325 - acc: 0.9434 - val_loss: 0.1411 - val_acc: 0.9429\n",
      "Epoch 89/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.1338 - acc: 0.9424 - val_loss: 0.1296 - val_acc: 0.9569\n",
      "Epoch 90/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.1374 - acc: 0.9433 - val_loss: 0.1475 - val_acc: 0.9477\n",
      "Epoch 91/100\n",
      "212/212 [==============================] - 226s 1s/step - loss: 0.1344 - acc: 0.9424 - val_loss: 0.1350 - val_acc: 0.9497\n",
      "Epoch 92/100\n",
      "212/212 [==============================] - 228s 1s/step - loss: 0.1329 - acc: 0.9425 - val_loss: 0.1305 - val_acc: 0.9501\n",
      "Epoch 93/100\n",
      "212/212 [==============================] - 226s 1s/step - loss: 0.1265 - acc: 0.9469 - val_loss: 0.1420 - val_acc: 0.9548\n",
      "Epoch 94/100\n",
      "212/212 [==============================] - 228s 1s/step - loss: 0.1337 - acc: 0.9438 - val_loss: 0.1307 - val_acc: 0.9480\n",
      "Epoch 95/100\n",
      "212/212 [==============================] - 228s 1s/step - loss: 0.1270 - acc: 0.9460 - val_loss: 0.1170 - val_acc: 0.9548\n",
      "Epoch 96/100\n",
      "212/212 [==============================] - 227s 1s/step - loss: 0.1227 - acc: 0.9469 - val_loss: 0.1311 - val_acc: 0.9582\n",
      "Epoch 97/100\n",
      "212/212 [==============================] - 226s 1s/step - loss: 0.1318 - acc: 0.9421 - val_loss: 0.1340 - val_acc: 0.9514\n",
      "Epoch 98/100\n",
      "212/212 [==============================] - 228s 1s/step - loss: 0.1247 - acc: 0.9456 - val_loss: 0.1498 - val_acc: 0.9487\n",
      "Epoch 99/100\n",
      "212/212 [==============================] - 226s 1s/step - loss: 0.1539 - acc: 0.9340 - val_loss: 0.1280 - val_acc: 0.9528\n",
      "Epoch 100/100\n",
      "212/212 [==============================] - 228s 1s/step - loss: 0.1331 - acc: 0.9414 - val_loss: 0.1235 - val_acc: 0.9535\n"
     ]
    }
   ],
   "source": [
    "img_gen_t = ImageDataGenerator(rotation_range=180,\n",
    "                               width_shift_range=0.3,\n",
    "                               height_shift_range=0.3,\n",
    "                               zoom_range=0.3,\n",
    "                               horizontal_flip=True,\n",
    "                               vertical_flip=True)\n",
    "\n",
    "train_generator = img_gen_t.flow_from_directory(\"/home/tsimage/high_speed_data/tct_data_samesize_0718_224/train\", \n",
    "                                                img_size, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "img_gen_v = ImageDataGenerator()\n",
    "valid_generator = img_gen_v.flow_from_directory(\"/home/tsimage/high_speed_data/tct_data_samesize_0718_224/valid\", \n",
    "                                                img_size, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "\n",
    "parallel_model.fit_generator(generator=train_generator, \n",
    "                             steps_per_epoch=train_imgs_num//batch_size, \n",
    "                             epochs=epochs, \n",
    "                             verbose=1,\n",
    "                             validation_data=valid_generator, \n",
    "                             validation_steps=valid_imgs_num//batch_size)\n",
    "\n",
    "model.save_weights(\"vgg19_finetune.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
